<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Siri-Like AI Assistant</title>
  <style>
    body {
      margin: 0;
      overflow: hidden;
      background: linear-gradient(120deg, #1abc9c, #16a085);
      animation: gradientShift 8s infinite;
      font-family: Arial, sans-serif;
    }
    canvas {
      display: block;
    }
    .message, .response {
      position: absolute;
      left: 50%;
      transform: translateX(-50%);
      padding: 10px 20px;
      background: rgba(0, 0, 0, 0.7);
      color: #ffffff;
      font-size: 14px;
      border-radius: 5px;
      display: none;
    }
    .message {
      bottom: 20px;
    }
    .response {
      top: 20px;
      color: #00ffcc;
    }
    @keyframes gradientShift {
      0% { background: linear-gradient(120deg, #1abc9c, #16a085); }
      50% { background: linear-gradient(120deg, #1abc9c, #2ecc71); }
      100% { background: linear-gradient(120deg, #1abc9c, #16a085); }
    }
  </style>
</head>
<body>
  <div id="message" class="message">Click to start recording...</div>
  <div id="response" class="response"></div>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/0.153.0/three.min.js"></script>
  <script>
    let isRecording = false; // 录音状态
    let mediaRecorder; // MediaRecorder 实例
    let audioChunks = []; // 存储录音数据

    // 初始化 Three.js 场景
    const scene = new THREE.Scene();
    const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
    const renderer = new THREE.WebGLRenderer({ antialias: true });
    renderer.setSize(window.innerWidth, window.innerHeight);
    document.body.appendChild(renderer.domElement);

    let smoothedVolume = 0; // 用于音量变化的平滑处理
    let speakingScale = 0; // 用于语音播放的动画

    const createSiriLikeEffect = () => {
      const group = new THREE.Group();

      // 外围光环
      const torusGeometry = new THREE.TorusGeometry(2, 0.1, 30, 100);
      const torusMaterial = new THREE.MeshBasicMaterial({
        color: 0x16a085,
        emissive: 0x1abc9c,
        emissiveIntensity: 0.8,
      });
      const torus = new THREE.Mesh(torusGeometry, torusMaterial);
      group.add(torus);

      // 中间 3D 球体
      const sphereGeometry = new THREE.SphereGeometry(0.5, 32, 32);
      const sphereMaterial = new THREE.MeshBasicMaterial({
        color: 0xffffff,
        emissive: 0x1abc9c,
        emissiveIntensity: 1.2,
      });
      const sphere = new THREE.Mesh(sphereGeometry, sphereMaterial);
      group.add(sphere);

      return { group, sphere };
    };

    const { group: siriEffect, sphere } = createSiriLikeEffect();
    scene.add(siriEffect);
    camera.position.z = 10;

    const animate = () => {
      siriEffect.rotation.y += 0.01; // 光环旋转
      siriEffect.rotation.x += 0.005; // 光环轻微倾斜

      // 中间球体动画：音量 + 语音播放双重控制
      const scale = 1 + smoothedVolume * 0.5 + speakingScale * 0.3; // 平滑变化
      sphere.scale.set(scale, scale, scale);

      renderer.render(scene, camera);
      requestAnimationFrame(animate);
    };
    animate();

    const startRecording = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(stream);
        audioChunks = [];

        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            audioChunks.push(event.data);
          }
        };

        mediaRecorder.onstop = async () => {
          const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
          const formData = new FormData();
          formData.append('audio', audioBlob, 'audio.wav');

          try {
            const response = await fetch('http://127.0.0.1:5000/api/audio', {
              method: 'POST',
              body: formData,
            });

            if (response.ok) {
              const result = await response.json();
              showResponse(result.message); // 显示后端返回内容
              playResponse(result.message); // 使用语音播放 AI 回复
            } else {
              showResponse("Error from server: " + response.statusText);
            }
          } catch (error) {
            console.error("Upload error:", error);
            showResponse("Failed to upload audio.");
          }
        };

        mediaRecorder.start();
        showMessage("Recording... Click again to stop.");
        isRecording = true;
      } catch (error) {
        console.error("Audio processing error:", error);
        showMessage("Unable to access microphone. Please check permissions.");
      }
    };

    const stopRecording = () => {
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
        showMessage("Uploading audio...");
        isRecording = false;
      }
    };

    // 使用 Web Speech API 播放语音
    const playResponse = (text) => {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'en-US'; // 设置语言
      utterance.rate = 1; // 播放速度
      utterance.pitch = 1; // 音调

      // 在语音播放过程中更新 speakingScale 动画
      utterance.onstart = () => {
        speakingScale = 1;
      };
      utterance.onend = () => {
        speakingScale = 0;
      };

      speechSynthesis.speak(utterance);
    };

    // 显示消息
    const messageBox = document.getElementById("message");
    const responseBox = document.getElementById("response");

    const showMessage = (msg) => {
      messageBox.textContent = msg;
      messageBox.style.display = "block";
    };

    const showResponse = (msg) => {
      responseBox.textContent = msg;
      responseBox.style.display = "block";
      setTimeout(() => {
        responseBox.style.display = "none";
      }, 5000);
    };

    // 点击屏幕开始/停止录音
    window.addEventListener("click", () => {
      if (isRecording) {
        stopRecording();
      } else {
        startRecording();
      }
    });
  </script>
</body>
</html>
